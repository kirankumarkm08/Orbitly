
MODEL_CMD_TEMPLATE=gpt4all --model ./models/gpt4all-lora.bin --prompt "{prompt}" --n_predict 128


MODEL_CMD_TEMPLATE=./main -m ./models/llama-2-7b.ggml.q4_0.bin -p "{prompt}" -n 128


